<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CMD LOCAL AI - PL / EN</title>
  <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600;700&display=swap');

    :root {
      --bg-0: #070b14;
      --bg-1: #0f172a;
      --line: #243145;
      --text: #dbe6f7;
      --muted: #8da2bf;
      --brand: #34d399;
      --brand-2: #38bdf8;
      --accent: #f59e0b;
    }

    * { box-sizing: border-box; }

    body {
      margin: 0;
      color: var(--text);
      font-family: 'JetBrains Mono', monospace;
      background:
        radial-gradient(1200px 500px at -10% -20%, #0b4f4a55, transparent 55%),
        radial-gradient(1000px 500px at 110% -30%, #1d4ed855, transparent 60%),
        linear-gradient(180deg, var(--bg-1), var(--bg-0));
      min-height: 100vh;
    }

    .card {
      border: 1px solid var(--line);
      background: linear-gradient(180deg, #0b1222cc, #090f1bcc);
      border-radius: 14px;
      backdrop-filter: blur(2px);
    }

    .fade-up {
      animation: fadeUp 0.55s ease both;
    }

    @keyframes fadeUp {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }

    .pill {
      border: 1px solid #2b3b57;
      border-radius: 9999px;
      padding: 0.25rem 0.7rem;
      color: var(--muted);
      background: #0d1628;
      font-size: 0.78rem;
      white-space: nowrap;
    }

    .k {
      color: #93c5fd;
      font-weight: 700;
    }

    .path {
      color: #86efac;
      font-weight: 700;
    }

    code {
      color: #f8fafc;
      background: #101b2d;
      border: 1px solid #293854;
      border-radius: 8px;
      padding: 0.1rem 0.45rem;
    }
  </style>
</head>
<body class="px-5 py-8 md:px-8 md:py-10">
  <main class="mx-auto max-w-6xl space-y-6">
    <section class="card p-6 md:p-8 fade-up">
      <div class="flex flex-wrap items-center justify-between gap-4">
        <div>
          <p class="text-sm tracking-wide" style="color: var(--brand-2);">LOCAL AI TOOLING</p>
          <h1 class="mt-2 text-3xl font-bold md:text-4xl">CMD LOCAL AI</h1>
          <p class="mt-3 text-sm md:text-base" style="color: var(--muted);">
            PL: Lokalna aplikacja AI (CLI + API kompatybilne z Ollama) do uruchamiania modeli GGUF przez <span class="k">llama-cpp-python</span>.<br>
            EN: Local AI app (CLI + Ollama-compatible API) for running GGUF models with <span class="k">llama-cpp-python</span>.
          </p>
        </div>
        <div class="flex flex-wrap gap-2">
          <span class="pill">GGUF</span>
          <span class="pill">CLI</span>
          <span class="pill">HTTP API</span>
          <span class="pill">Local First</span>
        </div>
      </div>

      <div class="mt-5 card p-4">
        <div class="text-sm" style="color: var(--muted);">Default server</div>
        <a href="http://localhost:8080" class="mt-1 inline-block text-lg font-semibold" style="color: var(--brand);">http://localhost:8080</a>
      </div>
    </section>

    <section class="grid gap-6 md:grid-cols-2">
      <article class="card p-6 fade-up">
        <h2 class="text-xl font-bold" style="color: var(--brand);">Polski</h2>

        <h3 class="mt-5 text-base font-semibold">Szybki start</h3>
        <ol class="mt-2 list-decimal space-y-2 pl-5" style="color: var(--muted);">
          <li>Wymagany Python 3.11+.</li>
          <li>Uruchom aplikacje: <code>py -3 run.py</code></li>
          <li>Zaladuj model: <code>load &lt;nazwa_pliku.gguf&gt;</code></li>
          <li>Rozmowa: <code>ai</code> lub <code>chat &lt;tekst&gt;</code></li>
        </ol>

        <h3 class="mt-5 text-base font-semibold">Komendy CLI</h3>
        <div class="mt-2 grid gap-2 text-sm" style="color: var(--muted);">
          <div><code>load</code> - wybor modelu z listy</div>
          <div><code>load &lt;name&gt;</code> - ladowanie modelu po nazwie</div>
          <div><code>models</code> - lista modeli GGUF</div>
          <div><code>catalog</code> - lista aliasow do pobierania</div>
          <div><code>download &lt;alias|url&gt; [file.gguf]</code> - pobieranie modelu</div>
          <div><code>pull &lt;alias|url&gt; [file.gguf]</code> - alias dla download</div>
          <div><code>ai</code> - tryb rozmowy (prompt <span class="k">AI&gt;</span>)</div>
          <div><code>chat &lt;tekst&gt;</code> - pojedyncza wiadomosc</div>
          <div><code>unload</code> - zwolnienie modelu z RAM</div>
          <div><code>status</code> - status aplikacji</div>
          <div><code>version</code> - wersja llama-cpp-python</div>
          <div><code>update</code> - aktualizacja runtime</div>
        </div>
      </article>

      <article class="card p-6 fade-up" style="animation-delay: 0.06s;">
        <h2 class="text-xl font-bold" style="color: var(--brand-2);">English</h2>

        <h3 class="mt-5 text-base font-semibold">Quick start</h3>
        <ol class="mt-2 list-decimal space-y-2 pl-5" style="color: var(--muted);">
          <li>Python 3.11+ is required.</li>
          <li>Run the app: <code>py -3 run.py</code></li>
          <li>Load a model: <code>load &lt;model_file.gguf&gt;</code></li>
          <li>Chat with model: <code>ai</code> or <code>chat &lt;text&gt;</code></li>
        </ol>

        <h3 class="mt-5 text-base font-semibold">CLI commands</h3>
        <div class="mt-2 grid gap-2 text-sm" style="color: var(--muted);">
          <div><code>load</code> - choose model from list</div>
          <div><code>load &lt;name&gt;</code> - load by filename</div>
          <div><code>models</code> - list local GGUF models</div>
          <div><code>catalog</code> - list downloadable aliases</div>
          <div><code>download &lt;alias|url&gt; [file.gguf]</code> - download model</div>
          <div><code>pull &lt;alias|url&gt; [file.gguf]</code> - alias for download</div>
          <div><code>ai</code> - chat mode (prompt <span class="k">AI&gt;</span>)</div>
          <div><code>chat &lt;text&gt;</code> - single message</div>
          <div><code>unload</code> - unload model from RAM</div>
          <div><code>status</code> - app status</div>
          <div><code>version</code> - llama-cpp-python version</div>
          <div><code>update</code> - runtime update</div>
        </div>
      </article>
    </section>

    <section class="card p-6 fade-up" style="animation-delay: 0.12s;">
      <h2 class="text-xl font-bold" style="color: var(--accent);">HTTP API</h2>
      <p class="mt-2 text-sm" style="color: var(--muted);">
        Compatible endpoints exposed on <span class="path">localhost:8080</span>:
      </p>
      <div class="mt-4 grid gap-2 text-sm md:grid-cols-2" style="color: var(--muted);">
        <div><code>GET /tags</code></div>
        <div><code>POST /generate</code></div>
        <div><code>POST /chat</code></div>
        <div><code>POST /pull</code></div>
        <div><code>GET /version</code></div>
      </div>
      <div class="mt-5 card p-4 text-sm" style="color: var(--muted);">
        <div>Example:</div>
        <div class="mt-2"><code>curl http://localhost:8080/tags</code></div>
        <div class="mt-2"><code>curl -X POST http://localhost:8080/chat -H "Content-Type: application/json" -d "{\"messages\":[{\"role\":\"user\",\"content\":\"Hello\"}]}"</code></div>
      </div>
    </section>

    <footer class="pb-3 pt-1 text-center text-xs" style="color: var(--muted);">
      <p>Notes: <code>models/</code> and large local binaries are excluded by <code>.gitignore</code>.</p>
      <p class="mt-1">Designed for fully local model execution.</p>
    </footer>
  </main>
</body>
</html>
